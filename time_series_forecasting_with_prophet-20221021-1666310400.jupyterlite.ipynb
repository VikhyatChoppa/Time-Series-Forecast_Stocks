{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "<center>\n    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"300\" alt=\"cognitiveclass.ai logo\">\n</center>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "The Library Prophet makes forecasting with time series a lot easier. Before the introduction of libraries like  Scikit-learn, coding a machine learning pipeline was quite tricky; now, all it takes is a few lines of code. Prophet kind of does for time series what Scikit-learn did for machine learning. We say almost because time seris analysis is usually more complicated than Machine learning, and Prophet makes your job a lot easyer \n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "In this Guided Project, we will go through one of the time series forecasting models, Prophet. We shall comprehend what prophet is and its benefits.\n - We'll go over two case studies.\n 1. Time series analysis of power consumption in India(2019-20) \n     - In this use case we are analyzing the usage consumption data that is available for the years 2019 and 2020, and we will be predicting        usage consumption for the years 2021 and 2022.\n 2. Time series analysis of Appliances count(2016)\n     - In this use case we are analyzing the Appliances which are used in January 2016 to May 2016, and we will be predicting appliances\n         for next five months which are June to Sept 2016.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## **Table of Contents**\n\n<ol>\n    <li><a href=\"https://#Time-series-Analysis\">Time series Analysis</a></li>\n    <li><a href=\"https://#Intoduction-to-Prophet\">Introduction to Prophet</a></li>\n     <li><a href=\"https://#benifits\">Benifits of Prophet</a></li>\n    <li><a href=\"https://#Setup\">Setup</a></li>\n    <ol><li><a href=\"https://#Installing-Required-Libraries\">Installing Required Libraries</a></li>\n    <li><a href=\"https://#Importing-Required-Libraries\">Importing Required Libraries</a></li></ol>  \n    <li><a href=\"https://#case-study\">Case Study</a></li>\n    <ol>\n        <li><a href=\"https://#Case-Study-1\">Time series analysis of power consumption in different states of India(2019-20)  </a>\n     <li><a href=\"https://#Case-Study-2\">Time series analysis of Appliances count(2016)</a>\n    </ol>\n    <li><a href=\"https://#Conclusion\">Conclusion</a>\n        \n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Time Series Analysis:\n\n - Time series data is a collection of observations of measurements gathered over regular or irregular intervals of time.\n - Time series data have a natural temporal ordering\n - E.g. Sales data for a specific product at different times of the year.\n \n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<center><img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-GPXX032NEN/images/time_series_img.jpg\" width=\"700\" height=\"400\"></center>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Introduction to Prophet\n - Prophet is a Python library that is open source and was created by Facebook primarily for time series forecasting.\n - It has the capability of automatically determining the right hyperparameters for the model.\n - It promotes insightful seasonal patterns.\n - It can fit time-series data having non-linearity in trends as well as holiday effects.\n - It has R and Python APIs for time-series forecasting\n \n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<center><img src=\"https://cdn.analyticsvidhya.com/wp-content/uploads/2018/05/tumblr_inline_omh3tnv5zk1r1x9ql_500.png\" width=\"700\" height=\"400\"></center> \n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Benefits of using prophet\n1. It's automatic as well as quick. For manual time series analysis and decomposition, it saves time.\n2. It generates reliable and precise models.\n3. It can deal with outliers and missing values.\n4. It can manage the effects of seasonality and holidays.\n5. It produces a tunable model.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": " \n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Structure of Prophet\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<center><img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-GPXX032NEN/images/prophet_structure-ImResizer.jpg\" width=\"700\" height=\"250\"></center>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Prophet is particularly good at modeling time series that have multiple seasonalities and doesn’t face the drawbacks of other algorithms. At its core is the sum of three functions of time plus an error term: \n1) growth g(t)\n2) seasonality s(t)\n3) holidays h(t) , and error e_t :\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<center><img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-GPXX032NEN/images/formula_prophet.png\" width=\"500\" height=\"350\"></center>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "An Additive Model above can absorb the absence of seasonal effects by having s(t) = 0, as the other terms of the equation have no impact to predict future values in y(t). Unlike, fixed and linear regression models like Fama.\nProphet is a modular and non — linear regression model that separates and recombines a single dataset of history. \nFeature Engineering when features explain a future value or when factors drive a forecast are removed.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Setup\n\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "For this lab, we will be using the following libraries:\n\n*   [`pandas`](https://pandas.pydata.org/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork31430127-2021-01-01) for managing the data.\n*   [`numpy`](https://numpy.org/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork31430127-2021-01-01) for mathematical operations.\n*   [`sklearn`](https://scikit-learn.org/stable/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork31430127-2021-01-01) for machine learning and machine-learning-pipeline related functions.\n*   [`matplotlib`](https://matplotlib.org/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork31430127-2021-01-01) for additional plotting tools.\n*   [`Plotly`](https://matplotlib.org/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork31430127-2021-01-01) for additional plotting tools.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Installing Required Libraries\n\nThe following required libraries are pre-installed in the Skills Network Labs environment. However, if you run this notebook commands in a different Jupyter environment (e.g. Watson Studio or Ananconda), you will need to install these libraries by removing the `#` sign before `!mamba` in the code cell below.\n\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# !pip install seaborn",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "ename": "<class 'AttributeError'>",
          "evalue": "module 'pexpect' has no attribute 'TIMEOUT'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msystem\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpip install seaborn\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/lib/python3.11/site-packages/IPython/core/interactiveshell.py:2629\u001b[0m, in \u001b[0;36mInteractiveShell.system_piped\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m   2624\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBackground processes not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2626\u001b[0m \u001b[38;5;66;03m# we explicitly do NOT return the subprocess status code, because\u001b[39;00m\n\u001b[1;32m   2627\u001b[0m \u001b[38;5;66;03m# a non-None value would trigger :func:`sys.displayhook` calls.\u001b[39;00m\n\u001b[1;32m   2628\u001b[0m \u001b[38;5;66;03m# Instead, we store the exit_code in user_ns.\u001b[39;00m\n\u001b[0;32m-> 2629\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_ns[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_exit_code\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43msystem\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvar_expand\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/lib/python3.11/site-packages/IPython/utils/_process_posix.py:129\u001b[0m, in \u001b[0;36mProcessHandler.system\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    125\u001b[0m enc \u001b[38;5;241m=\u001b[39m DEFAULT_ENCODING\n\u001b[1;32m    127\u001b[0m \u001b[38;5;66;03m# Patterns to match on the output, for pexpect.  We read input and\u001b[39;00m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;66;03m# allow either a short timeout or EOF\u001b[39;00m\n\u001b[0;32m--> 129\u001b[0m patterns \u001b[38;5;241m=\u001b[39m [\u001b[43mpexpect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTIMEOUT\u001b[49m, pexpect\u001b[38;5;241m.\u001b[39mEOF]\n\u001b[1;32m    130\u001b[0m \u001b[38;5;66;03m# the index of the EOF pattern in the list.\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;66;03m# even though we know it's 1, this call means we don't have to worry if\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;66;03m# we change the above list, and forget to change this value:\u001b[39;00m\n\u001b[1;32m    133\u001b[0m EOF_index \u001b[38;5;241m=\u001b[39m patterns\u001b[38;5;241m.\u001b[39mindex(pexpect\u001b[38;5;241m.\u001b[39mEOF)\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'pexpect' has no attribute 'TIMEOUT'"
          ],
          "output_type": "error"
        }
      ],
      "execution_count": 4
    },
    {
      "cell_type": "code",
      "source": "!mamba uninstall pexpect\n\n# All Libraries required for this lab are listed below. The libraries pre-installed on Skills Network Labs are commented.\n# !mamba install -qy pandas==1.3.4 numpy==1.21.4 seaborn==0.9.0 matplotlib==3.5.0 scikit-learn==0.20.1\n# Note: If your environment doesn't support \"!mamba install\", use \"!pip install\"\n# !pip install  pandas==1.3.4 numpy==1.21.4 seaborn==0.9.0 matplotlib==3.5.0 scikit-learn==0.20.1\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "ename": "<class 'AttributeError'>",
          "evalue": "module 'pexpect' has no attribute 'TIMEOUT'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msystem\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmamba uninstall pexpect\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# All Libraries required for this lab are listed below. The libraries pre-installed on Skills Network Labs are commented.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# !mamba install -qy pandas==1.3.4 numpy==1.21.4 seaborn==0.9.0 matplotlib==3.5.0 scikit-learn==0.20.1\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Note: If your environment doesn't support \"!mamba install\", use \"!pip install\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# !pip install  pandas==1.3.4 numpy==1.21.4 seaborn==0.9.0 matplotlib==3.5.0 scikit-learn==0.20.1\u001b[39;00m\n",
            "File \u001b[0;32m/lib/python3.11/site-packages/IPython/core/interactiveshell.py:2629\u001b[0m, in \u001b[0;36mInteractiveShell.system_piped\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m   2624\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBackground processes not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2626\u001b[0m \u001b[38;5;66;03m# we explicitly do NOT return the subprocess status code, because\u001b[39;00m\n\u001b[1;32m   2627\u001b[0m \u001b[38;5;66;03m# a non-None value would trigger :func:`sys.displayhook` calls.\u001b[39;00m\n\u001b[1;32m   2628\u001b[0m \u001b[38;5;66;03m# Instead, we store the exit_code in user_ns.\u001b[39;00m\n\u001b[0;32m-> 2629\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_ns[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_exit_code\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43msystem\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvar_expand\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/lib/python3.11/site-packages/IPython/utils/_process_posix.py:129\u001b[0m, in \u001b[0;36mProcessHandler.system\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    125\u001b[0m enc \u001b[38;5;241m=\u001b[39m DEFAULT_ENCODING\n\u001b[1;32m    127\u001b[0m \u001b[38;5;66;03m# Patterns to match on the output, for pexpect.  We read input and\u001b[39;00m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;66;03m# allow either a short timeout or EOF\u001b[39;00m\n\u001b[0;32m--> 129\u001b[0m patterns \u001b[38;5;241m=\u001b[39m [\u001b[43mpexpect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTIMEOUT\u001b[49m, pexpect\u001b[38;5;241m.\u001b[39mEOF]\n\u001b[1;32m    130\u001b[0m \u001b[38;5;66;03m# the index of the EOF pattern in the list.\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;66;03m# even though we know it's 1, this call means we don't have to worry if\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;66;03m# we change the above list, and forget to change this value:\u001b[39;00m\n\u001b[1;32m    133\u001b[0m EOF_index \u001b[38;5;241m=\u001b[39m patterns\u001b[38;5;241m.\u001b[39mindex(pexpect\u001b[38;5;241m.\u001b[39mEOF)\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'pexpect' has no attribute 'TIMEOUT'"
          ],
          "output_type": "error"
        }
      ],
      "execution_count": 3
    },
    {
      "cell_type": "markdown",
      "source": "The following required libraries are **not** pre-installed in the Skills Network Labs environment. **You will need to run the following cell** to install them:\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### After running below command Restart the kernel\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "!pip install --upgrade nbformat",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "### Note : Restart the Kernel After updating nbformat\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "!pip install prophet",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "ename": "<class 'AttributeError'>",
          "evalue": "module 'pexpect' has no attribute 'TIMEOUT'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msystem\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpip install prophet\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/lib/python3.11/site-packages/IPython/core/interactiveshell.py:2629\u001b[0m, in \u001b[0;36mInteractiveShell.system_piped\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m   2624\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBackground processes not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2626\u001b[0m \u001b[38;5;66;03m# we explicitly do NOT return the subprocess status code, because\u001b[39;00m\n\u001b[1;32m   2627\u001b[0m \u001b[38;5;66;03m# a non-None value would trigger :func:`sys.displayhook` calls.\u001b[39;00m\n\u001b[1;32m   2628\u001b[0m \u001b[38;5;66;03m# Instead, we store the exit_code in user_ns.\u001b[39;00m\n\u001b[0;32m-> 2629\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_ns[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_exit_code\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43msystem\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvar_expand\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/lib/python3.11/site-packages/IPython/utils/_process_posix.py:129\u001b[0m, in \u001b[0;36mProcessHandler.system\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    125\u001b[0m enc \u001b[38;5;241m=\u001b[39m DEFAULT_ENCODING\n\u001b[1;32m    127\u001b[0m \u001b[38;5;66;03m# Patterns to match on the output, for pexpect.  We read input and\u001b[39;00m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;66;03m# allow either a short timeout or EOF\u001b[39;00m\n\u001b[0;32m--> 129\u001b[0m patterns \u001b[38;5;241m=\u001b[39m [\u001b[43mpexpect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTIMEOUT\u001b[49m, pexpect\u001b[38;5;241m.\u001b[39mEOF]\n\u001b[1;32m    130\u001b[0m \u001b[38;5;66;03m# the index of the EOF pattern in the list.\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;66;03m# even though we know it's 1, this call means we don't have to worry if\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;66;03m# we change the above list, and forget to change this value:\u001b[39;00m\n\u001b[1;32m    133\u001b[0m EOF_index \u001b[38;5;241m=\u001b[39m patterns\u001b[38;5;241m.\u001b[39mindex(pexpect\u001b[38;5;241m.\u001b[39mEOF)\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'pexpect' has no attribute 'TIMEOUT'"
          ],
          "output_type": "error"
        }
      ],
      "execution_count": 3
    },
    {
      "cell_type": "markdown",
      "source": "# About Dataset\n## Context\nIndia is the world's third-largest producer and third-largest consumer of electricity. The national electric grid in India has an installed capacity of 370.106 GW as of 31 March 2020. Renewable power plants, which also include large hydroelectric plants, constitute 35.86% of India's total installed capacity. During the 2018-19 fiscal year, the gross electricity generated by utilities in India was 1,372 TWh and the total electricity generation (utilities and non-utilities) in the country was 1,547 TWh. The gross electricity consumption in 2018-19 was 1,181 kWh per capita. \nIn 2015-16, electric energy consumption in agriculture was recorded as being the highest (17.89%) worldwide. The per capita electricity consumption is low compared to most other countries despite India having a low electricity tariff.\n\nIn light of the recent COVID-19 situation, when everyone has been under lockdown for the months of April & May the impacts of the lockdown on economic activities have been faced by every sector in a positive or a negative way. \nWith the electricity consumption being so crucial to the country, we came up with a plan to study the impact on energy consumption state and region wise.\n\nThe dataset is exhaustive in its demonstration of energy consumption state wise.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Content\nData is in the form of a time series for a period of 17 months beginning from 2nd Jan 2019 till 23rd May 2020.\n\n    Rows are indexed with dates and columns represent states.\n    Rows and columns put together, each datapoint reflects the power consumed in Mega Units (MU) by the given state (column) at the given date (row).\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "*   Kaggle Source - [https://www.kaggle.com/datasets/twinkle0705/state-wise-power-consumption-in-india)\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Importing Required Libraries\n\n*We recommend you import all required libraries in one place (here):*\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import pandas as pd\nfrom prophet import Prophet\nfrom matplotlib import pyplot\nfrom matplotlib.pyplot import figure\nfrom sklearn.metrics import mean_absolute_error\nimport plotly.express as px\nimport plotly.graph_objects as go\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "# CASE STUDY 1 - Time series analysis of power consumption in India(2019-20)\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Read CSV file\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Read a comma-separated values (csv) file into DataFrame.\n\n<code>Parameters</code>\nfilepath_or_bufferstr, path object or file-like object Any valid string path is acceptable. \n\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "df=pd.read_csv('https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-GPXX032NEN/images/data/long_data_.csv')",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "### Print the dataset information\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "```DataFrame_Name.head``` function returns the first n rows for the object based on position. \n\n It is useful for quickly testing if your object has the right type of data in it.\n\n For negative values of n, this function returns all rows except the last |n| rows, equivalent to df[:n]\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "df.head()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "\n```DataFrame_Name.shape``` gives us the ```dimension``` of the dataset (columns, rows) therefor, we have six timer series (rows) of length 16599 columns\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "df.shape",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "### Check All column Datatypes\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "```dtypes``` function returns a Series with the data type of each column. \n\nThe result’s index is the original DataFrame’s columns. Columns with mixed types are stored with the object dtype.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "df.dtypes",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## Format Dates column into datetime type\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "A ```to_datetime``` function converts a scalar, array-like, Series or DataFrame/dict-like to a pandas datetime object.\n\nHere we have convert ```Dates``` column to ```datetime``` object as it was in ```object``` type and for prophet model we need datetime type.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "df['Dates'] = pd.to_datetime(df['Dates'])",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## Group by Dates\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "A ```groupby``` operation involves some combination of splitting the object, applying a function, and combining the results. \n\n\nHere we  ```groupby``` our dataframe using the ```Dates``` column. This is because we have different states of data so we will find average usage for all the states.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "df=df.groupby('Dates',as_index=False).mean()\nprint(df.head())",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Dataset shape is 498 because we have approx 1 year 5 months of data\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "print(df.shape) ",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "### select the datetime column and target column\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Here We are selecting only 2 columns which are needed for time series forecasting as prophet model needs dataframe with 2 columns\n\n1) Datetime column (Dates)\n\n2) Target column (Usage)\n\nTo ```select multiple columns```, use a ``list`` of ``column names`` within the selection brackets.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "df=df[['Dates','Usage']]",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "You can also use drop function to drop unnecessary column by using, drop specifying  labels from rows or columns.\n\nAxis=0 can be used for dropping particular Rows.\n\nAxis=1 can be used for dropping particular Columns.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "##optional if you are using above command\n##df.drop(['latitude','longitude'],inplace=True,axis=1)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## Introduction to Plotly library\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<center><img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-GPXX032NEN/images/Untitled%20design%20%289%29.png\" width=\"550\" height=\"550\"></center>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "You’ve probably heard about ```Matplotib and Seaborn``` since they are often mentioned in Data Science courses. \nBut do you know these libraries are designed for ```basic plotting```.\nTherefore here we have used ```Plotly``` library to plot our time series data.\n\nThe ```plotly``` Python library is an ```interactive, open-source``` plotting library that supports over 40 unique chart types covering a wide range of statistical, financial, geographic, scientific, and 3-dimensional use-cases.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "You can simply install plotly using below command.\n\n```pip install plotly```\n\n### Features of Plotly:\n1) zoom\n2) pan \n3) hover over datapoint.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Plot the Data\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "\n\n```X cordinates``` will represent ```Dates``` column from dataframe (df).\n\n```Y cordinates``` will represent target column which is ```Usage``` column from dataframe (df).\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "fig = px.line(df, x='Dates', y='Usage')\nfig.show()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "### Prepare for Prophet  \n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "For prophet to work, we need to change the names of these columns to 'ds' and 'y'.\n\nWe will convert datetime column to ds and target column to y.\n\nds - datestamp column\n\ny - target column\n\nDataFrame.columns attribute return the column labels of the given Dataframe.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "df.columns = ['ds','y']",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "### Print 5 rows of the Dataframe \n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Now you can see columns names are changed to ```ds``` and ```y```\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "df.head()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "### Initialize the Model\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "We fit the model by ```instantiating a new Prophet object```. Any settings to the forecasting procedure are passed into the constructor. \n\nThen you call the fit method and pass in the historical dataframe. \n\nFitting should take 1-7 seconds.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "model=Prophet()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "### Fit the model to dataframe (df)\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "The ```fit()``` function takes a DataFrame of time series data. The DataFrame must have a specific format. \n\nThe first column must have the name ```ds``` and contain the date-times. \n\nThe second column must have the name ```y``` and contain the observations.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "model.fit(df)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "### Print Model Components\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "If you want to see the forecast components, you can use the Prophet.plot_components method. \n\nBy default you’ll see the trend, yearly seasonality, and weekly seasonality of the time series. If you include holidays, you’ll see those here, too.\n\nIn this time series, the seasonality is not a constant additive factor as assumed by Prophet, rather it grows with the trend. This is multiplicative seasonality.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "model.component_modes",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "### Make Future Dataframe\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "A ```make_future_dataframe``` function Make dataframe with future dates for forecasting.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "#### Arguments:\n<table height=\"40%\",width=\"60%\" style=\"font-size:16px;\">\n    \n<tr><td>periods</td><td> - </td> <td>Int number of periods to forecast forward.</td></tr>\n\n<tr><td>freq</td><td> - </td> <td>'day', 'week', 'month', 'quarter', 'year', 1(1 sec), 60(1 minute) or 3600(1 hour).</td></tr>\n\n<tr><td>include_history</td><td> - </td> <td>Boolean to include the historical dates in the data frame for predictions.</td></tr>\n   \n</table>\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "future_dates = model.make_future_dataframe(periods=365,freq='d',include_history=True)\nfuture_dates.shape",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Print the future_dates datframe first 5 rows.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "future_dates.head()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "### Prediction of the model\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "To predict, we use the predict() method and pass in the future dataframe as shown below.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "prediction=model.predict(future_dates)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "#### From the results generated, the model has generated a lot of information in addition to the predicted ds and yhat column. \n#### The most important column is the ```yhat column```, as it is what represents your ```Usage forecast```.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "yhat upper values and yhate lower values - Uncertainity Interval\n\nThere are three sources of uncertainty in the forecast:\n 1) uncertainty in the trend. \n 2) uncertainty in the seasonality estimates.\n 3) additional observation noise.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "prediction.head()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "### Plot The Prediction\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "The ```scatter trace``` type encompasses ```line charts, scatter charts, text charts, and bubble charts.```\n\nThe data visualized as scatter point or lines is set in x and y. Text (appearing either on the chart or on hover only) is via text.\n\nParameteres:\n- x – Sets the x coordinates.\n- y – Sets the y coordinates.\n- mode – Determines the drawing mode for this scatter trace. \n  If there are less than 20 points and the trace is not stacked then the default is “lines+markers”. Otherwise, “lines”.\n- name - Sets the trace name. The trace name appear as the legend item and on hover.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "trace_open = go.Scatter(\n    x = prediction[\"ds\"],\n    y = prediction[\"yhat\"],\n    mode = 'lines',\n    name=\"Forecast\"\n)\ntrace_high = go.Scatter(\n    x = prediction[\"ds\"],\n    y = prediction[\"yhat_upper\"],\n    mode = 'lines',\n    fill = \"tonexty\", \n    line = {\"color\": \"#57b8ff\"}, \n    name=\"Higher uncertainty interval\"\n)\ntrace_low = go.Scatter(\n    x = prediction[\"ds\"],\n    y = prediction[\"yhat_lower\"],\n    mode = 'lines',\n    fill = \"tonexty\", \n    line = {\"color\": \"#57b8ff\"}, \n    name=\"Lower uncertainty interval\"\n)\ntrace_close = go.Scatter(\n    x = df[\"ds\"],\n    y = df[\"y\"],\n    name=\"Data values\"\n)\n\n#make list for all three scattle objects.\ndata = [trace_open,trace_high,trace_low,trace_close]\n# Construct a new Layout object. \n#title - It will display string as a title of graph\nlayout = go.Layout(title=\"Power consumption forecasting\")\n#A list or tuple of trace instances (e.g. [Scatter(…), Bar(…)]) or A single trace instance (e.g. Scatter(…), Bar(…), etc.)\n#A list or tuple of dicts of string/value properties where: - The ‘type’ property specifies the trace type.\n\nfig = go.Figure(data=data)\nfig.show()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "### Plot the Actual v/s Predicted Without Optimization\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "\nfig = go.Figure([go.Scatter(x=df['ds'], y=df['y'],mode='lines',\n                    name='Actual')])\n#You can add traces using an Express plot by using add_trace\nfig.add_trace(go.Scatter(x=prediction['ds'], y=prediction['yhat'],\n                   mode='lines+markers',\n                    name='predicted'))\n#To display a figure using the renderers framework, you call the .show() method on a graph object figure, or pass the figure to the plotly.io.show function. \n#With either approach, plotly.py will display the figure using the current default renderer(s).\nfig.show()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## Mean Absolute Error\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Let us now understand the MAE (Mean Absolute Error).\nAbsolute error refers to the magnitude of difference between the prediction of an observation and the true value of that observation.\nIt is thus an arithmetic average of the absolute errors $MAE=\\frac{1}{n}\\sum_{i=1}^{n}|x_i-y_i|$ where ``` y{i}``` is the prediction and ```x{i}``` the true value. Note that alternative formulations may include relative frequencies as weight factors. The mean absolute error uses the same scale as the data being measured. This is known as a scale-dependent accuracy measure and therefore cannot be used to make comparisons between series using different scales.\n\n### MAE Range is from 0 to ∞ (infinite). The lower the MAE, the better a model fits a dataset.\n\n<center><img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-GPXX032NEN/images/MAE_img.png\" width=\"600\" height=\"500\"></center> \n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Here we are getting ```7.9``` MAE which is good but optimizing model can help to reduced Errors.\n\nIn previous graph of predicted V/s Actual we can see that curves are not perfect for prediction.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#Return a Numpy representation of the DataFrame.\ny_true = df['y'].values\n\n#Here we have specified [:498] because in y_true we have 498 data points so for comparing both series we need equal shape of series.\ny_pred = prediction['yhat'][:498].values \n\n#Parameters:\n#y_truearray-like of shape = (n_samples) or (n_samples, n_outputs)\n#Ground truth (correct) target values.\n\n#y_predarray-like of shape = (n_samples) or (n_samples, n_outputs)\n#Estimated target values.\n\nmae = mean_absolute_error(y_true, y_pred)\nprint('MAE: %.3f' % mae)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## Optimizing the model for better forecasting\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<table  style=' font-size: 16px;'>\n<tr><td>name  <td>String name of the seasonality component.</td></tr>\n<tr><td> period</td> <td> Float number of days in one period.</td></tr>\n<tr><td> fourier_order</td> <td> Int number of Fourier components to use.</td></tr>\n<tr><td> prior_scale</td> <td> Optional float prior scale for this component. </td></tr>\n<tr><td> mode</td> <td> Optional 'additive' or 'multiplicative'.</td></tr>\n<tr><td> condition_name </td> <td> String name of the seasonality condition.</td></tr>\n</table>\n \n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Prophet will by default fit weekly and yearly seasonalities, if the time series is more than two cycles long.\n\nIt will also fit daily seasonality for a sub-daily time series. \n\nYou can add other seasonalities (monthly, quarterly, hourly) using the add_seasonality method (Python)\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "#### Here we have taken period=365, as one year consist of 365 days and Fourier_order=70.\n#### In this case study, I have randomly found 70 is a good fit for my model. \n#### Fourier_order can differ for different datasets.\n#### Note : Higher Furier_order Value can lead to Overfitting.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "model1=Prophet(daily_seasonality=True).add_seasonality(name='yearly',period=365,fourier_order=70)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "### Fit Model with Hyper Patameter Tuning \n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "The ```fit()``` function takes a ```DataFrame``` of ```time series data```. \n\nThe DataFrame must have a specific format.\n\nThe ```first column``` must have the name ```'ds'``` and contain the ```date-times.``` .\n\nThe ```second column``` must have the name ```'y'``` and contain the ```observations```.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "model1.fit(df)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "### Print the components of model\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "model1.component_modes",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "### Make future dataframe for next 1 year\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Here we are taking period = 365 beacause we have 365 days in a year.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "future_dates1=model1.make_future_dataframe(periods=365)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "### Predict the Datapoint for next year.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "prediction1=model1.predict(future_dates1)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "#### After optimization, we are getting the value of MAE as 5.6, which is better than above MAE i.e 7.9. Hence This model gives a good Prediction.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from sklearn.metrics import mean_absolute_error\ny_true = df['y'].values\ny_pred = prediction1['yhat'][:498].values\nmae = mean_absolute_error(y_true, y_pred)\nprint('MAE: %.3f' % mae)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "### Plot expected vs actual After Optimizng\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import plotly.graph_objects as go\nfig = go.Figure([go.Scatter(x=df['ds'], y=df['y'],mode='lines',\n                    name='Actual')])\n\nfig.add_trace(go.Scatter(x=prediction1['ds'], y=prediction1['yhat'],\n                   mode='lines+markers',\n                    name='predicted'))\n\nfig.show()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## CASE STUDY 2 - Time series analysis of Appliances count (2016)\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "*   Kaggle Source - [https://www.kaggle.com/code/callherro/energy-data/data)\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#read CSV file\ndf=pd.read_csv('https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-GPXX032NEN/images/data/energydata_complete.csv')",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "#display dataframe\ndf.head()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "### 1. Select date column and target column\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#To do - Your code goes here",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "\n<details><summary>Solution</summary>\n\n```python\ndf=df[['date','Appliances']]\n\n```\n\n</details>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### 2. Plot dataframe\n\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#To do - Your code goes here",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "\n<details><summary>Solution</summary>\n\n```python\ndf.plot()\n\n```\n\n</details>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### 3. Rename column to ds and y\n    ds - datestamp column\n    y - target column\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#To do - Your code goes here",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "\n<details><summary>Solution</summary>\n\n```python\ndf.columns = ['ds','y']\ndf.head()\n```\n\n</details>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### 4. Intialize model\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#To do - Your code goes here",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "\n<details><summary>Solution</summary>\n\n```python\nmodel=Prophet()\n\n```\n\n</details>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### 5. Fit model\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#To do - Your code goes here",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "\n<details><summary>Solution</summary>\n\n```python\nmodel.fit(df)\n\n```\n\n</details>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### 6. Print model components\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#To do - Your code goes here",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "\n<details><summary>Solution</summary>\n\n```python\nmodel.component_modes\n\n```\n\n</details>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### 7. Create future dates of 150 days\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#To do - Your code goes here",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "\n<details><summary>Solution</summary>\n\n```python\nfuture_dates=model.make_future_dataframe(periods=150)\n\n```\n\n</details>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### 8. Predict the target for next 150 days\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#To do - Your code goes here",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "\n<details><summary>Solution</summary>\n\n```python\nprediction=model.predict(future_dates)\n\n```\n\n</details>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### 9. Find MAE (Mean Absolute Error)\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#To do - Your code goes here",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "\n<details><summary>Solution</summary>\n\n```python\n\ny_true = df['y'].values\ny_pred = prediction['yhat'][:19735].values\nmae = mean_absolute_error(y_true, y_pred)\nprint('MAE: %.3f' % mae)\n\n```\n\n</details>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "# Conclusion\nWow! With three small changes to the hyperparameters i.e name,period and fourier_order, we have a pretty accurate model of prophet. \n\nIt quickly helps us to find insightful predictions on the time series analysis problem and also deal with outliers.\n\nFrom this casestudy we have also learn about plotly, Mean Absolute Error and Prophet's Hyper parameter tuning.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Author\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "[Jigisha Barbhaya](https://www.linkedin.com/in/jigisha-barbhaya/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkGuidedProjectsIBMGPXX032NEN123-2022-01-01)\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Other Contibutors\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "[Joseph Santarcangelo](https://www.linkedin.com/in/joseph-s-50398b136/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkML311Coursera35714171-2022-01-01)\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Copyright © 2022 IBM Corporation. All rights reserved.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}